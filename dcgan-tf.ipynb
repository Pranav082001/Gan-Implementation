{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-28T14:13:36.512560Z","iopub.execute_input":"2021-10-28T14:13:36.513763Z","iopub.status.idle":"2021-10-28T14:13:36.542822Z","shell.execute_reply.started":"2021-10-28T14:13:36.513630Z","shell.execute_reply":"2021-10-28T14:13:36.541763Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2021-10-28T14:13:36.545819Z","iopub.execute_input":"2021-10-28T14:13:36.546419Z","iopub.status.idle":"2021-10-28T14:14:01.521653Z","shell.execute_reply.started":"2021-10-28T14:13:36.546369Z","shell.execute_reply":"2021-10-28T14:14:01.520535Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport gdown\nfrom tqdm import tqdm\nfrom zipfile import ZipFile","metadata":{"execution":{"iopub.status.busy":"2021-10-28T14:17:33.845176Z","iopub.execute_input":"2021-10-28T14:17:33.845523Z","iopub.status.idle":"2021-10-28T14:17:33.850301Z","shell.execute_reply.started":"2021-10-28T14:17:33.845490Z","shell.execute_reply":"2021-10-28T14:17:33.849514Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"os.makedirs(\"celeba_gan\")\n\nurl = \"https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\"\noutput = \"celeba_gan/data.zip\"\ngdown.download(url, output, quiet=True)\n\nwith ZipFile(\"celeba_gan/data.zip\", \"r\") as zipobj:\n    zipobj.extractall(\"celeba_gan\")\n","metadata":{"execution":{"iopub.status.busy":"2021-10-28T14:14:09.473543Z","iopub.execute_input":"2021-10-28T14:14:09.473834Z","iopub.status.idle":"2021-10-28T14:15:09.240182Z","shell.execute_reply.started":"2021-10-28T14:14:09.473790Z","shell.execute_reply":"2021-10-28T14:15:09.238000Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataset = keras.preprocessing.image_dataset_from_directory(\n    \"celeba_gan\", label_mode=None, image_size=(64, 64), batch_size=32,shuffle=True\n)\ndataset = dataset.map(lambda x: x / 255.0)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T14:15:09.245751Z","iopub.execute_input":"2021-10-28T14:15:09.246559Z","iopub.status.idle":"2021-10-28T14:15:17.803878Z","shell.execute_reply.started":"2021-10-28T14:15:09.246479Z","shell.execute_reply":"2021-10-28T14:15:17.801917Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"for x in dataset:\n    plt.axis(\"off\")\n    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n    break","metadata":{"execution":{"iopub.status.busy":"2021-10-28T14:15:17.805587Z","iopub.execute_input":"2021-10-28T14:15:17.805966Z","iopub.status.idle":"2021-10-28T14:15:18.231835Z","shell.execute_reply.started":"2021-10-28T14:15:17.805919Z","shell.execute_reply":"2021-10-28T14:15:18.230600Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"discriminator = keras.Sequential(\n    [\n        keras.Input(shape=(64, 64, 3)),\n        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Flatten(),\n        layers.Dropout(0.2),\n        layers.Dense(1, activation=\"sigmoid\"),\n    ],\n    name=\"discriminator\",\n)\ndiscriminator.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-28T14:15:18.233371Z","iopub.execute_input":"2021-10-28T14:15:18.233770Z","iopub.status.idle":"2021-10-28T14:15:18.382391Z","shell.execute_reply.started":"2021-10-28T14:15:18.233720Z","shell.execute_reply":"2021-10-28T14:15:18.380958Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"latent_dim=128\n\ngenerator=keras.Sequential([\n    layers.Input(shape=(latent_dim,)),\n    layers.Dense(8 * 8 * 128),\n    layers.Reshape((8,8,128)),\n    layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n    layers.LeakyReLU(alpha=0.2),\n    layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n    layers.LeakyReLU(alpha=0.2),\n    layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n    layers.LeakyReLU(alpha=0.2),\n    layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n])\n\nprint(generator.summary())","metadata":{"execution":{"iopub.status.busy":"2021-10-28T14:15:18.385044Z","iopub.execute_input":"2021-10-28T14:15:18.386784Z","iopub.status.idle":"2021-10-28T14:15:18.539043Z","shell.execute_reply.started":"2021-10-28T14:15:18.386712Z","shell.execute_reply":"2021-10-28T14:15:18.538086Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"opt_gen=keras.optimizers.Adam(1e-4)\nopt_disc=keras.optimizers.Adam(1e-4)\nloss_fn=keras.losses.BinaryCrossentropy()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T14:15:18.540351Z","iopub.execute_input":"2021-10-28T14:15:18.540668Z","iopub.status.idle":"2021-10-28T14:15:18.546896Z","shell.execute_reply.started":"2021-10-28T14:15:18.540637Z","shell.execute_reply":"2021-10-28T14:15:18.545831Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-10-28T14:18:18.656449Z","iopub.execute_input":"2021-10-28T14:18:18.656765Z","iopub.status.idle":"2021-10-28T14:18:18.662598Z","shell.execute_reply.started":"2021-10-28T14:18:18.656728Z","shell.execute_reply":"2021-10-28T14:18:18.661441Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"os.mkdir(\"gen_images\")","metadata":{"execution":{"iopub.status.busy":"2021-10-28T14:18:54.644080Z","iopub.execute_input":"2021-10-28T14:18:54.644408Z","iopub.status.idle":"2021-10-28T14:18:54.648789Z","shell.execute_reply.started":"2021-10-28T14:18:54.644374Z","shell.execute_reply":"2021-10-28T14:18:54.647794Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"for epoch in range(10):\n    for idx, (real) in enumerate(tqdm(dataset)):\n        batch_size = real.shape[0]\n        with tf.GradientTape() as gen_tape:\n            random_latent_vectors = tf.random.normal(shape = (batch_size, latent_dim))\n            fake = generator(random_latent_vectors)\n\n        if idx % 10 == 0:\n            img = keras.preprocessing.image.array_to_img(fake[0])\n            img.save(\"gen_images/generated_img_%03d_%d.png\" % (epoch, idx))\n\n        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n        with tf.GradientTape() as disc_tape:\n            loss_disc_real = loss_fn(tf.ones((batch_size, 1)), discriminator(real))\n            loss_disc_fake = loss_fn(tf.zeros((batch_size, 1)), discriminator(fake))\n            loss_disc = (loss_disc_real + loss_disc_fake)/2\n\n        grads = disc_tape.gradient(loss_disc, discriminator.trainable_weights)\n        opt_disc.apply_gradients(\n            zip(grads, discriminator.trainable_weights)\n        )\n\n        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n        with tf.GradientTape() as gen_tape:\n            fake = generator(random_latent_vectors)\n            output = discriminator(fake)\n            loss_gen = loss_fn(tf.ones(batch_size, 1), output)\n\n        grads = gen_tape.gradient(loss_gen, generator.trainable_weights)\n        opt_gen.apply_gradients(zip(grads, generator.trainable_weights))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-28T14:21:43.581025Z","iopub.execute_input":"2021-10-28T14:21:43.581388Z","iopub.status.idle":"2021-10-28T15:02:16.192018Z","shell.execute_reply.started":"2021-10-28T14:21:43.581342Z","shell.execute_reply":"2021-10-28T15:02:16.189492Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}